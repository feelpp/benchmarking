<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>1. Introduction to ReFrame-HPC and initial benchmark setups :: Benchmarking</title>
    <link rel="canonical" href="https://feelpp.github.io/benchmarking/benchmarking/training/reframe/index.html">
    <meta name="generator" content="Antora 3.1.10">
    <link rel="stylesheet" href="../../../_/css/site.css">
<link rel="icon" href="../../../_/img/favicon.ico" type="image/x-icon">
<script>!function(l,p){if(l.protocol!==p&&l.host=="docs.antora.org"){l.protocol=p}else if(/\.gitlab\.io$/.test(l.host)){l.replace(p+"//docs.antora.org"+l.pathname.substr(l.pathname.indexOf("/",1))+l.search+l.hash)}}(location,"https:")</script>

<script src="../../../_/js/vendor/tabs-block-extension.js"></script>
<script src="../../../_/js/vendor/tabs-block-behavior.js"></script>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },

  TeX: {
      Macros: {
      bold: ["{\\bf #1}",1],
      calTh: "{\\mathcal{T}_h}",
      card: ["{\\operatorname{card}(#1)}",1],
      card: ["{\\operatorname{card}(#1)}",1],
      Ck: ["{\\mathcal{C}^{#1}}",1],
      deformt: ["{\\mathbf{\\varepsilon(#1)}}",1],
      diam: "{\\operatorname{diam}}",
      dim: ["{\\operatorname{dim}(#1)}",1],
      disp: ["{\\mathbf{#1}}",1],
      domain: "{\\Omega}",
      ds: "",
      essinf: "{\\operatorname{ess}\\, \\operatorname{inf}}",
      F:"{\\mathcal{F}}",
      geo: "{\\mathrm{geo}}",
      Ich: ["{\\mathcal{I}^{#1}_{c,h}#2}",2],
      Id: "{\\mathcal{I}}",
      Ilag: ["{\\mathcal{I}^{\\mathrm{lag}}_{#1}}",1],
      jump: ["{[\\![ #1 ]\\!]}",1],
      n:"{\\mathbf{n}}",
      Ne: "{N_{\\mathrm{e}}}",
      Next: "{\\mathrm{n}}",
      nf: "{n_f}",
      ngeo: "{n_{\\mathrm{geo}}}",
      Nma: "{N_{\\mathrm{ma}}}",
      NN: "{\\mathbb N}",
      Nno: "{N_{\\mathrm{no}}}",
      Nso: "{N_{\\mathrm{so}}}",
      opdim: "{\\operatorname{dim}}",
      p: "{\\mathrm{p}}",
      P:"{\\mathcal{P}}",
      Pch: ["{P^{#1}_{c,h}}",1],
      Pcho: ["{P^{#1}_{c,h,0}}",1],
      Pk: ["{\\mathcal{P}^{#1}}",1],
      poly: ["{\\mathbb{#1}",1],
      poly: ["{\\mathbb{#1}}",1],
      prect: ["{\\left\\(#1\\right\\)}",1],
      q:"{\\mathbf{q}}",
      Qch: ["{Q^{#1}_{c,h}}",1],
      Qk: ["{\\mathcal{Q}^{#1}}",1],
      R: ["{\\mathbb{R}^{#1}}",1],
      RR: "{\\mathbb R}",
      set: ["{\\left\\{#1\\right\\}}",1],
      stresst: ["{\\mathbf{\\sigma(#1)}}",1],
      T:"{\\mathcal{T}}",
      tr: "{\\operatorname{tr}}",
      v:"{\\mathbf{v}}",
      vertiii: ["\\left\\vert\\kern-0.25ex\\left\\vert\\kern-0.25ex\\left\\vert #1 \\right\\vert\\kern-0.25ex\\right\\vert\\kern-0.25ex\\right\\vert",1]
  },
  extensions: ["mhchem.js"] 
  }
});
</script>
<!--<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_CHTML'></script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>-->

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>-->
<script>var uiRootPath = '../../../_'</script>

  </head>
  <body class="article">
<header class="header">
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark navbar-template-project" style="border-top: 4px solid #9E9E9E">
        <div class="navbar-brand">
            <div class="navbar-item feelpp-logo">
                <a href="https://feelpp.github.io/benchmarking">Benchmarking</a>
            </div>
            <button class="navbar-burger" data-target="topbar-nav">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>

        <div id="topbar-nav" class="navbar-menu">
            <div class="navbar-end">
                <div class="navbar-item">
                    <a href="https://docs.feelpp.org/">Documentation Reference</a>
                </div>
                <div class="navbar-item has-dropdown is-hoverable download-item">
                    <div class="navbar-item"><a href="https://docs.feelpp.org/user/latest/install/index.html" class="download-btn">Get Feel++</a></div>
                </div>
                <div class="navbar-item">
                    <a class="navbar-brand"  href="https://www.cemosis.fr">
                        <img class="cemosis-logo"  src="../../../_/img/cemosis-logo.svg" alt="Cemosis logo"/>
                    </a>
                </div>
            </div>
        </div>
    </nav>
</header>
<div class="body">
<a href="#" class="menu-expand-toggle"></a>
<div class="nav-container" data-component="benchmarking" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../../index.html">The Feel++ Benchmarking Project</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../../index.html">Benchmarks</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../../tutorial/index.html">Documentation</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../../tutorial/gettingstarted.html">Getting Started</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../../tutorial/configuration.html">Configuration Guide</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../../tutorial/configurationfiles/system.html">System Configuration</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../../tutorial/configurationfiles/magicstrings.html">Magic Strings</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../../tutorial/configurationfiles/machine.html">Machine Configuration</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../../tutorial/configurationfiles/benchmark.html">Benchmark Configuration</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../../tutorial/configurationfiles/plots.html">Plots Configuration</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../index.html">Training</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Introduction to <em>feelpp.benchmarking</em></a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="introduction.html">Overview</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="settings.html">System Settings</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="machine_specs.html">Machine Specifications</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="example_app.html">Example Application</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="benchmark_specs.html">Benchmark Specifications</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="plot_specs.html">Plot Specifications</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="executing.html">Executing the Benchmark</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="handsOn/index.html">Hands-on session 1</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="handsOn/exercise1.html">Exercise 1</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="handsOn/exercise2.html">Exercise 2</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../advanced/index.html">Advanced Usage of <em>feelpp.benchmarking</em></a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../advanced/containers.html">Configuring Containers</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../advanced/remote_files.html">Handling Remote Files</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../advanced/file_dependencies.html">Handling File Dependencies</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../advanced/custom_perfvars.html">Custom Performance Variables</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../advanced/memory.html">Memory Management</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../advanced/visualization.html">Visualization</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../advanced/workflow.html">Continuous Benchmarking Workflow</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../advanced/handsOn/index.html">Hands-on session 2</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">The Feel++ Benchmarking Project</span>
    <span class="version"></span>
  </div>
  <ul class="components">
      <li class="component is-current">
        <a class="title" href="../../index.html">The Feel++ Benchmarking Project</a>
      </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
  <button class="nav-toggle"></button>
    <a href="../../index.html" class="home-link"></a>
  <nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../../index.html">The Feel++ Benchmarking Project</a></li>
    <li><a href="../index.html">Training</a></li>
    <li><a href="index.html">Introduction to <em>feelpp.benchmarking</em></a></li>
  </ul>
</nav>

  
    <div class="edit-this-page"><a href="https://github.com/feelpp/benchmarking/edit/master/docs/modules/training/pages/reframe/index.adoc">Edit this Page</a></div>
  
  <div class="page-downloads">
  <span class="label">Download as</span>
  <ul class="download-options">
    <li>
      <a onclick="print(this)" href="#" data-toggle="tooltip" data-placement="left" title="Print to PDF"
         class="pdf-download">
        <img class="pdf-file-icon icon" src="../../../_/img/pdf.svg"/> .pdf
      </a>
    </li>
  </ul>
</div>
</div>

  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">1. Introduction to ReFrame-HPC and initial benchmark setups</h1>
<div id="preamble">
<div class="sectionbody">
<div class="dlist">
<dl>
<dt class="hdlist1">What you will learn in this course</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p>The basics of ReFrame-HPC</p>
</li>
<li>
<p>How to run a simple benchmark using <em>feelpp.benchmarking</em></p>
</li>
<li>
<p>How to create figures to visualize benchmarking results, using <em>feelpp.benchmarking</em></p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_overview_of_reframe_hpc_and_feelpp_benchmarking"><a class="anchor" href="#_overview_of_reframe_hpc_and_feelpp_benchmarking"></a>1. Overview of ReFrame-HPC and feelpp.benchmarking</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_what_is_feelpp_benchmarking"><a class="anchor" href="#_what_is_feelpp_benchmarking"></a>1.1. What is feelpp.benchmarking ?</h3>
<div class="paragraph">
<p><em>feelpp.benchmarking</em> is a framework designed to automate and facilitate the benchmarking process for any application. It is built on top of <a href="https://github.com/reframe-hpc/reframe">ReFrame-HPC</a>, and was conceived to simplify benchmarking on any HPC system. The framework is specially useful for centralizing benchmarking results and ensuring reproducibility.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="../_images/bench_supercomputers.png" alt="feelpp.benchmarking Supercomputers" width="75%">
</div>
</div>
<div class="sect3">
<h4 id="_motivation"><a class="anchor" href="#_motivation"></a>1.1.1. Motivation</h4>
<div class="paragraph">
<p>Benchmarking an HPC application can often be an error-prone process, as the benchmarks need to be configured for multiple systems. If evaluating multiple applications, a benchmarking pipeline needs to be created for each one of them.
This is where <em>feelpp.benchmarking</em> comes in hand, as it allows users to run reproducible and consistent benchmarks for their applications on different architectures without manually handling execution details.</p>
</div>
<div class="paragraph">
<p>The framework&#8217;s customizable configuration files make it adaptable to various scenarios.
Whether you&#8217;re optimizing code, comparing hardware, or ensuring the reliability of numerical simulations, <em>feelpp.benchmarking</em> offers a structured, scalable, and user-friendly solution to streamline the benchmarking process.</p>
</div>
</div>
<div class="sect3">
<h4 id="_how_it_works"><a class="anchor" href="#_how_it_works"></a>1.1.2. How it works</h4>
<div class="paragraph">
<p>The framework requires 4 configuration files, in JSON format, in order to set up a benchmark.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">4 configuration files</dt>
<dd>
<div class="dlist">
<dl>
<dt class="hdlist1">System settings (ReFrame)</dt>
<dd>
<p>Describes the system architecture (e.g. partitions, environments, available physical memory, devices)</p>
</dd>
<dt class="hdlist1">Machine Specifications</dt>
<dd>
<p>Filters the environments to benchmark, specifies access, I/O directories and test execution policies.</p>
</dd>
<dt class="hdlist1">Benchmark/Application Specifications</dt>
<dd>
<p>Describes how to execute the application, where and how to extract performance variables, and the test parametrization.</p>
</dd>
<dt class="hdlist1">Figure configuration</dt>
<dd>
<p>Describes how to build the generated report&#8217;s plots</p>
</dd>
</dl>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Once the files are built and <em>feelpp.benchmarking</em> is launched, a pre-processing phase begins where configuration files are parse. After this, the ReFrame test pipeline is executed according to the provided configuration.</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Pre-processing stage</dt>
<dd>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Configuration files are parsed to replace <strong>placeholders</strong>.</p>
</li>
<li>
<p>If a container image is being benchmarked, this one is pulled and placed on the provided destination.</p>
</li>
<li>
<p>If there are remote file dependencies, they are downloaded to the specified destinations.</p>
</li>
</ol>
</div>
</dd>
<dt class="hdlist1">ReFrame test pipeline</dt>
<dd>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>The parameter space is created.</p>
</li>
<li>
<p>Tests are dispatched.</p>
</li>
<li>
<p>Computing resources are set, along with specific launcher and scheduler options.</p>
</li>
<li>
<p>Jobs are submitted by the scheduler.</p>
</li>
<li>
<p>Performance variables are extracted.</p>
</li>
<li>
<p>Sanity checks</p>
</li>
<li>
<p>Cleanup</p>
</li>
</ol>
</div>
</dd>
</dl>
</div>
<div class="paragraph">
<p>Finally, at the end phase of the pipeline, <em>feelpp.benchmarking</em> will store the ReFrame report following a specific folder structure.
This will allow the framework to handle multiple ReFrame reports in order to render them in a dashboard-like website.</p>
</div>
<div class="paragraph">
<p>The diagram figure summarizes the <em>feelpp.benchmarking</em> workflow.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="../_images/benchmark_code_design.png" alt="feelpp.benchmarking sequence diagram">
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_what_is_reframe_hpc"><a class="anchor" href="#_what_is_reframe_hpc"></a>1.2. What is ReFrame-HPC ?</h3>
<div class="imageblock">
<div class="content">
<img src="../_images/reframe_logo-width400p.png" alt="ReFrame Logo">
</div>
</div>
<div class="quoteblock">
<blockquote>
ReFrame is a powerful framework for writing system regression tests and benchmarks, specifically targeted to HPC systems. The goal of the framework is to abstract away the complexity of the interactions with the system, separating the logic of a test from the low-level details, which pertain to the system configuration and setup. This allows users to write portable tests in a declarative way that describes only the test&#8217;s functionality.
</blockquote>
<div class="attribution">
&#8212; <a href="https://github.com/reframe-hpc/reframe">ReFrame in a Nutshell</a>
</div>
</div>
<div class="sect3">
<h4 id="_core_features"><a class="anchor" href="#_core_features"></a>1.2.1. Core features</h4>
<div class="dlist">
<dl>
<dt class="hdlist1">Regression testing</dt>
<dd>
<p>Ensures that new changes do not introduce errors by re-running existing test cases.</p>
</dd>
<dt class="hdlist1">Performance evaluation</dt>
<dd>
<p>Monitors and assesses the performance of applications to detect any regressions or improvements.</p>
</dd>
<dt class="hdlist1">Performance and Sanity checks</dt>
<dd>
<p>Automates validation of test results with built-in support for performance benchmarks, ensuring correctness and efficiency.</p>
</dd>
</dl>
</div>
</div>
<div class="sect3">
<h4 id="_test_execution_pipeline"><a class="anchor" href="#_test_execution_pipeline"></a>1.2.2. Test Execution Pipeline</h4>
<div class="paragraph">
<p>ReFrame tests go through a pre-defined pipeline where users can customize the what happens in between each step by using decorators (e.g. <code>@run_after("setup")</code>).</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Setup: Tests are set up for current partition and programming environment.</p>
</li>
<li>
<p>Compile: If needed, the script for test compilation is created and submitted for execution.</p>
</li>
<li>
<p>Run: Scripts associated to the test execution are submitted (asynchronously or sequentially).</p>
</li>
<li>
<p>Sanity: The test outputs are checked to validate the correct execution.</p>
</li>
<li>
<p>Performance: Performance metrics are collected.</p>
</li>
<li>
<p>Cleanup: Test resources are cleaned up.</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="../_images/reframe-test-cases.svg" alt="How ReFrame loads and schedules tests for execution">
</div>
</div>
<div id="examp:1" class="sidebarblock examp">
<div class="content">
<div class="title">Example Pipeline</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import reframe as rfm
import reframe.utility.sanity as sn

@rfm.simple_test
class SleepTest(rfm.RunOnlyRegressionTest):
    valid_systems = ['*']
    valid_prog_environs = ['*']

    executable = 'bash'
    executable_opts = ['-c']
    seconds_to_sleep = parameter([1,2,3])

    @run_after("init")
    def setReferences(self):
        self.reference = {
            '*': {
                'sleepTime': (self.seconds_to_sleep,-0.05,0.05,'s')
            }
        }

    @run_before("run")
    def setExecutableOpts(self):
        self.executable_opts += [f'''
            SECONDS=0;
            sleep {self.seconds_to_sleep};
            duration=$SECONDS;
            echo "slept for $duration s";
            echo "I'm done sleeping!";
        ''']

    @sanity_function
    def validateExecution(self):
        return sn.assert_found("I'm done sleeping!", self.stdout)

    @performance_function('s')
    def sleepTime(self):
        return sn.extractsingle(f'slept for (\d+)\s+s',self.stdout,1,float)</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>For those interested in learning more, check out:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Official ReFrame Documentation: <a href="https://reframe-hpc.readthedocs.io" class="bare">reframe-hpc.readthedocs.io</a></p>
</li>
<li>
<p>GitHub Repository: <a href="https://github.com/reframe-hpc" class="bare">github.com/reframe-hpc</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_reframes_system_configuration_file"><a class="anchor" href="#_reframes_system_configuration_file"></a>2. ReFrame&#8217;s System Configuration File</h2>
<div class="sectionbody">
<div class="paragraph">
<p><em>feelpp.benchmarking</em> makes use of <a href="https://reframe-hpc.readthedocs.io/en/stable/config_reference.html:">ReFrame&#8217;s Configuration files</a> to set up multiple HPC systems.</p>
</div>
<div class="paragraph">
<p>These files describe the system&#8217;s architecture, as well as the necessary modules, partitions, commands and environments for your applications to run as expected.</p>
</div>
<div class="paragraph">
<p>System configuration files can be provided as a JSON file, or as a Python script where the configuration is stored as a dictionary in a variable named <code>site_configuration</code>.</p>
</div>
<div id="examp:2" class="sidebarblock examp">
<div class="content">
<div class="title">Very simple configuration file</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">site_configuration = {
    'systems': [
        {
            'name': 'my_system',
            'descr': 'Very simple example system',
            'hostnames':['py::socket.gethostname'],
            'partitions': [
                {
                    'name': 'my_partition',
                    'scheduler': 'local',
                    'launcher': 'mpiexec',
                    'environs': ['my_environment'],
                    'processor': { 'num_cpus': 4 }
                }
            ]
        }
    ],
    'environments': [
        {
            'name': 'my_environment',
            'modules': [],
            'target_systems': ['my_system:my_partition']
        }
    ]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Built-in supercomputers config</dt>
<dd>
<div class="ulist">
<ul>
<li>
<p><strong>Discoverer</strong>. Sofia, Bulgaria.</p>
</li>
<li>
<p><strong>Vega</strong>. Maribor, Slovenia.</p>
</li>
<li>
<p><strong>MeluXina</strong>. Bissen, Luxembourg.</p>
</li>
<li>
<p><strong>Karolina</strong>. Ostrava, Czechia.</p>
</li>
<li>
<p><strong>Gaya</strong>. Strasbourg, France.</p>
</li>
<li>
<p><strong>LUMI</strong>. Kajaani, Finland. [SOON]</p>
</li>
</ul>
</div>
</dd>
</dl>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>There is no need to write system configurations for built-in systems. Users can specify them directly on the machine specification JSON.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="sect2">
<h3 id="_system_partitions_and_environments"><a class="anchor" href="#_system_partitions_and_environments"></a>2.1. System partitions and Environments</h3>
<div class="paragraph">
<p>According to <a href="https://reframe-hpc.readthedocs.io/en/stable/tutorial.html#systems-and-environments">ReFrame&#8217;s documentation</a>, "a system is an abstraction of an HPC system that is managed by a workload manager. A system can comprise multiple partitions, which are collection of nodes with similar characteristics".
And "an environment is an abstraction of the environment where a test will run and it is a collection of environment variables, environment modules and compiler definitions".</p>
</div>
<div class="imageblock">
<div class="content">
<img src="../_images/reframe-system-arch.svg" alt="ReFrame system architecture">
</div>
</div>
<div class="exampleblock">
<div class="title">Example 1. Karolina system</div>
<div class="content">
<div class="paragraph">
<p>Karolina has defined a <strong>qcpu</strong> partition consisting of 720, and a <strong>qgpu</strong> partition consisting of 72 nodes equiped with GPU a accelerator.
The entire list of Karolina&#8217;s partitions can be found <a href="https://docs.it4i.cz/general/karolina-partitions/?h=partition">here</a>.</p>
</div>
<div class="paragraph">
<p>Now, a user might define a programming environment that uses Python3.8, and another environment that uses Python3.13.</p>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_system_specific_parameters"><a class="anchor" href="#_system_specific_parameters"></a>2.2. System specific parameters</h3>
<div class="paragraph">
<p>It can be useful to specify some configurations, like the maximum number of jobs that can be submitted asynchronously, additional launcher options, or the available memory per node.</p>
</div>
<div id="examp:3" class="sidebarblock examp">
<div class="content">
<div class="title">Specify custom launcher options</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    "systems":[{
        "partitions":[{
            "resources": [{
                "name":"launcher_options",
                "options":["-bind-to","core"]
            }]
        }]
    }]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock warning">
<table>
<tr>
<td class="icon">
<i class="fa icon-warning" title="Warning"></i>
</td>
<td class="content">
<div class="paragraph">
<p><em>feelpp.benchmarking</em> requires to set the <code>systems.partitions.processor.num_cpus</code> value for each provided partition to indicate the maximum number of logical CPUs per partition&#8217;s node.</p>
</div>
</td>
</tr>
</table>
</div>
<div id="examp:4" class="sidebarblock examp">
<div class="content">
<div class="title">Karolina&#8217;s Configuration File</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    "systems": [
        {
            "name": "karolina",
            "descr": "karolina",
            "hostnames": ["login\d+.karolina.it4i.cz","cn\d+.karolina.it4i.cz"],
            "modules_system": "lmod",
            "partitions": [
                {
                    "name": "qcpu",
                    "scheduler": "slurm",
                    "launcher": "srun",
                    "max_jobs": 8,
                    "access": ["--partition=qcpu"],
                    "environs": ["default"],
                    "processor": {
                        "num_cpus": 128
                    },
                    "devices": [
                        {
                            "type": "cpu",
                            "num_devices":829
                        }
                    ],
                    "container_platforms":[
                        {
                            "type": "Singularity"
                        }
                    ],
                    "extras":{
                        "memory_per_node":256
                    }
                }
            ]
        }
    ],
    "environments": [
        {
            "name": "default",
            "modules": ["OpenMPI/4.1.4-GCC-12.2.0","apptainer"],
            "target_systems": ["karolina:qcpu"]
        }
    ]
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_machine_specification_file"><a class="anchor" href="#_machine_specification_file"></a>3. Machine Specification File</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When benchmarking an application, users must tell <em>feelpp.benchmarking</em> in which system the tests will run. To do this, a machine specification JSON file should be provided.</p>
</div>
<div class="paragraph">
<p>This configuration file will not only filter partitions and environments for the tests, but also specifies access to the target systems (if needed). Users can also specify some input and output directories path that are common for all benchmarked applications.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Thanks to <em>feelpp.benchmarking</em>'s {{placeholder}} syntax, multiple configuration fields can be refactored inside this file.</p>
</div>
</td>
</tr>
</table>
</div>
<div id="examp:mspec" class="sidebarblock examp">
<div class="content">
<div class="title">Basic machine configuration file</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    "machine": "default",

    "partitions":["my_partition"],
    "prog_environments":["my_environment"],

    "reframe_base_dir":"$PWD/build/reframe",
    "reports_base_dir":"$PWD/reports/",

    "input_dataset_base_dir":"$PWD/input_data",
    "output_app_dir":"$PWD/outputs"
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_example_benchmarking_the_time_complexity_of_sorting_algorithms"><a class="anchor" href="#_example_benchmarking_the_time_complexity_of_sorting_algorithms"></a>4. Example: Benchmarking the time complexity of sorting algorithms</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To exemplify what <em>feelpp.benchmarking</em> can do, a good test case is to benchmark the time complexity of sorting algorithms.</p>
</div>
<div class="paragraph">
<p>The framework provides an example python application that sorts a random list of integers using different sorting algorithms.
This application takes the following arguments:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>-n</code>: the number of elements in the list to sort</p>
</li>
<li>
<p><code>-a</code>: The algorithm to use for sorting. Options are <code>bubble</code>, <code>insertion</code>, <code>merge</code></p>
</li>
<li>
<p><code>-o</code>: The output file to write execution time. It will be written in JSON format (<code>{"elapsed": 0.0}</code>)</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>This example can be recreated with the following python code:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Bubble sort</dt>
</dl>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">def bubbleSort(array):
    n = len(array)
    is_sorted = True
    for i in range(n):
        for j in range( n - i - 1 ):
            if array[j] &gt; array[j+1]:
                array[j],array[j+1] = array[j+1], array[j]
                is_sorted = False
        if is_sorted:
            break
    return array</code></pre>
</div>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Insertion sort</dt>
</dl>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">def insertionSort(array):
    n = len(array)
    for i in range(1,n):
        key_item = array[i]
        j = i - 1
        while j&gt;=0 and array[j] &gt; key_item:
            array[j+1]=array[j]
            j-=1
        array[j+1] = key_item
    return array</code></pre>
</div>
</div>
</div>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Merge sort</dt>
</dl>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">def merge(left,right):
    if not left:
        return right
    if not right:
        return left
    result = []
    left_i = right_i = 0
    while len(result) &lt; len(left) + len(right):
        if left[left_i] &lt;= right[right_i]:
            result.append(left[left_i])
            left_i+=1
        else:
            result.append(right[right_i])
            right_i+=1

        if right_i == len(right):
            result += left[left_i:]
            break

        if left_i == len(left):
            result += right[right_i:]
            break

    return result


def mergeSort(array):
    if len(array) &lt; 2:
        return array
    mid = len(array) // 2
    return merge( left = self.sort(array[:mid]), right=self.sort(array[mid:]) )</code></pre>
</div>
</div>
</div>
</div>
<div class="paragraph">
<p>Then, the main function that parses the arguments and calls the sorting algorithm can be defined as follows:</p>
</div>
<div class="dlist">
<dl>
<dt class="hdlist1">Main function</dt>
</dl>
</div>
<div class="exampleblock">
<div class="content">
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from argparse import ArgumentParser
from time import perf_counter
import numpy as np
import os, json

if __name__=="__main__":
    #Parse the arguments
    parser = ArgumentParser()
    parser.add_argument('-n',help="Number of elements")
    parser.add_argument('--algorithm','-a', help="Sorting algorithm to use")
    parser.add_argument('--out','-o', help="Filepath where to save elapsed time")
    args = parser.parse_args()

    #Generate a random list of integers
    n = int(float(args.n))
    array = np.random.randint(min(-1000,-n),max(1000,n),n).tolist()

    #Select the sorting algorithm
    if args.algorithm == "bubble":
        alg = bubbleSort
    elif args.algorithm == "insertion":
        alg = insertionSort
    elif args.algorithm == "merge":
        alg = mergeSort
    else:
        raise NotImplementedError(f"Sorting algorithm - {args.algorithm} - not implemented")

    #Sort the array and measure the elapsed time
    start_time = perf_counter()
    sorted_array = alg(array)
    end_time = perf_counter()
    elapsed_time = end_time - start_time

    #Create the folder if it does not exist
    folder = os.path.dirname(args.out)
    if not os.path.exists(folder):
        os.makedirs(folder)

    #Save the elapsed time
    with open(args.out,'w') as f:
        json.dump({"elapsed": elapsed_time},f)</code></pre>
</div>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>At the moment, <em>feelpp.benchmarking</em> only supports extracting performance metrics from JSON and CSV files.
Very soon, extracting metrics from stdout and plain text files will be supported, using regular expressions.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_benchmark_specification_file"><a class="anchor" href="#_benchmark_specification_file"></a>5. Benchmark Specification File</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This configuration file describes precisely what will be benchmarked. It is used to specify the parameter space for the benchmarking process, the application executable and its arguments, as well as where to find performance variables and how to validate tests.</p>
</div>
<div class="paragraph">
<p>The basic skeleton of the JSON file is the following:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    //A given name for your Use Case
    "use_case_name":"my_use_case",

    //The maximum time the submitted job can run. After this, it will be killed.
    "timeout":"0-0:5:0",

    //Where to find the application.
    "executable":"my_app.sh",

    // Application options
    "options": ["-my-flag","--my-option=1"],

    // How many computational resources to use for the benchmark, and how
    "resources": {},

    // Performance values extraction
    "scalability": {},

    // Check if test succesfull
    "sanity":{},

    // Test parametrization
    "parameters":[]
}</code></pre>
</div>
</div>
<div class="sect2">
<h3 id="_magic_strings"><a class="anchor" href="#_magic_strings"></a>5.1. Magic strings</h3>
<div class="paragraph">
<p><em>feelpp.benchmarking</em> is equiped with a special <strong>{{placeholder}}</strong> syntax that replaces values from a json field into another. This syntax is specially helpful for refactoring the configuration file.
However, the main objective of this syntax is to access values assigned during the test, like parameter values or the test ID.
It is also possible to access values from the machine specifications file.</p>
</div>
</div>
<div class="sect2">
<h3 id="_parameters"><a class="anchor" href="#_parameters"></a>5.2. Parameters</h3>
<div class="paragraph">
<p>The parameter field consists of a list of <strong>Parameter</strong> objects that contain the values for which the test will be executed.</p>
</div>
<div id="examp:6" class="sidebarblock examp">
<div class="content">
<div class="title">Simple parameter</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    "name":"my_parameter",
    "sequence":[1,2,3]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Specifying uniquely this parameter implies that ReFrame will launch 3 tests, one for each value of <code>my_parameter</code>.</p>
</div>
</div>
</div>
<div class="paragraph">
<p>It must be noted that ReFrame will consider the cartesian product of the <code>parameters</code> list in order to launch the tests.</p>
</div>
<div id="examp:7" class="sidebarblock examp">
<div class="content">
<div class="title">Cartesian product of parameters</div>
<div class="paragraph">
<p>For the following parameters section</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">[
    {"name":"param1", "sequence":[1,2]},
    {"name":"param2", "sequence":["a","b"]}
]</code></pre>
</div>
</div>
<div class="paragraph">
<p>4 tests will be launched, taking the values:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>param1 = 1, param2 = "a"</p>
</li>
<li>
<p>param1 = 2, param2 = "a"</p>
</li>
<li>
<p>param1 = 1, param2 = "b"</p>
</li>
<li>
<p>param1 = 2, param2 = "b"</p>
</li>
</ul>
</div>
</div>
</div>
<div class="paragraph">
<p>The framework is equiped with multiple parameter generators that simplifies having to manually specify all desired parameters. For example, users can provide a range or a linspace <em>function</em>.</p>
</div>
<div id="examp:8" class="sidebarblock examp">
<div class="content">
<div class="title">Parameter configuration for sorting algorithms benchmark</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">"parameters": [
    {
        "name": "algorithm",
        "sequence": [ "bubble", "insertion", "merge" ]
    },
    {
        "name":"elements",
        //Equivalent to [10,100,1000,10000]
        "geomspace":{
            "min":10,
            "max":10000,
            "n_steps":4
        }
    }
]</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
12 tests will be executed for this parameter combination
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="paragraph">
<p>Finally, parameter values can be accessed -on the go- by other configuration fields by using the placeholder syntax and appending the reserved keyword <code>.value</code>. i.e.
<code>"{{parameters.my_param.value}}"</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_application_setup"><a class="anchor" href="#_application_setup"></a>5.3. Application setup</h3>
<div class="paragraph">
<p>The executable and options fields specify the command that will be executed for the benchmark. The executable defines the application or script to run, while the options array contains command-line arguments passed to it. Users can use placeholders to reference parameters or system variables dynamically.</p>
</div>
<div id="examp:9" class="sidebarblock examp">
<div class="content">
<div class="title">App setup for sorting algorithms benchmark</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
"executable": "python3 {{machine.input_dataset_base_dir}}/sorting/sortingApp",
"timeout":"0-0:5:0",
"options":[
    "-n {{parameters.elements.value}}",
    "-a {{parameters.algorithm.value}}",
    "-o {{output_directory}}/{{instance}}/outputs.json"
]
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_resources"><a class="anchor" href="#_resources"></a>5.4. Resources</h3>
<div class="paragraph">
<p>Users can specify the computing resources for which the tests will run, and can even parametrize this.</p>
</div>
<div class="paragraph">
<p>A combination of (tasks, tasks_per_node, gpus_per_node, nodes, memory and exclusive_access) can be specified. However, only certain combinations are supported, and at least one must be provided.</p>
</div>
<div id="examp:10" class="sidebarblock examp">
<div class="content">
<div class="title">Parametrized resources</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
"resources":{
    "tasks":"{{parameters.tasks.value}}",
    "nodes":1,
    "exclusive_access":false

},
"parameters":[
    {"name":"tasks","sequence":[16,32,64,128]}
]
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_performance_values_extraction"><a class="anchor" href="#_performance_values_extraction"></a>5.5. Performance Values Extraction</h3>
<div class="paragraph">
<p>The <code>scalability</code> field defines how performance metrics are extracted from output files. Users first need to specify the base directory where performance variables are written. Then, users should provide the list of all the performance files, along with the file format. For JSON files, a <code>variables_path</code> field should be passed indicating how to extract the variables from the dictionary structure.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
At the moment supported formats are : CSV and JSON
</td>
</tr>
</table>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
Wildcards (<code>*</code>) are supported for extracting variables from deeply nested or complex JSON structures.
</td>
</tr>
</table>
</div>
<div id="examp:11" class="sidebarblock examp">
<div class="content">
<div class="title">Performance extraction for sorting algorithms benchmark</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">"scalability": {
    "directory": "{{output_directory}}/{{instance}}/",
    "stages": [
        {
            "name":"",
            "filepath": "outputs.json",
            "format": "json",
            "variables_path":"elapsed"
        }
    ]
}</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_test_validation"><a class="anchor" href="#_test_validation"></a>5.6. Test validation</h3>
<div class="paragraph">
<p>The <code>sanity</code> field is used to ensure the correct execution of a test. It contains two lists: <code>success</code> and <code>error</code>. The framework will look for all text patterns in the <code>success</code> list and will force the test to fail if the patterns are not found.
Analogously, tests will fail if the patterns in the <code>error</code> list are found.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
Only validating the standard output is supported for now.
</td>
</tr>
</table>
</div>
<div id="examp:12" class="sidebarblock examp">
<div class="content">
<div class="title">Validating a tests execution</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">"sanity": {
    "success": ["[SUCCESS]"],
    "error": ["[OOPSIE]","Error"]
}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_full_example_configuration_file"><a class="anchor" href="#_full_example_configuration_file"></a>5.6.1. Full Example Configuration File</h4>
<div class="paragraph">
<p>The full configuration file for a sorting algorithms benchmark can be found below:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    "use_case_name": "sorting",
    "timeout":"0-0:5:0",
    "output_directory": "{{machine.output_app_dir}}/sorting",

    "executable": "python3 {{machine.input_dataset_base_dir}}/sorting/sortingApp",
    "options": [
        "-n {{parameters.elements.value}}",
        "-a {{parameters.algorithm.value}}",
        "-o {{output_directory}}/{{instance}}/outputs.json"
    ],
    "resources":{ "tasks":1, "exclusive_access":false },

    "scalability": {
        "directory": "{{output_directory}}/{{instance}}/",
        "stages": [
            {
                "name":"",
                "filepath": "outputs.json",
                "format": "json",
                "variables_path":"elapsed"
            }
        ]
    },
    "sanity": { "success": [], "error": [] },

    // Test parameters
    "parameters": [
        {
            "name": "algorithm",
            "sequence": [ "bubble", "insertion", "merge" ]
        },
        {
            "name":"elements",
            //Equivalent to [10,100,1000,10000]
            "geomspace":{
                "min":10,
                "max":10000,
                "n_steps":4
            }
        }
    ]
}</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_figure_specifications"><a class="anchor" href="#_figure_specifications"></a>6. Figure specifications</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The final configuration file that must be provided to the <em>feelpp.benchmarking</em> framework is the plot specifications file. This file contains the information necessary to generate the plots that will be displayed in the report.</p>
</div>
<div class="paragraph">
<p>It has a flexible syntax that allows users to build figures depending on the benchmark parameters.</p>
</div>
<div class="paragraph">
<p>The file should contain a single field: <code>plots</code>, which is a list of <strong>Plot</strong> objects.</p>
</div>
<div class="paragraph">
<p>The figures will appear in the report in the order they are defined in the file.</p>
</div>
<div class="paragraph">
<p>Users should specify the plot type and which data to use for different axis.</p>
</div>
<div class="paragraph">
<p>Additionally, a <code>transformation</code> field can be provided to apply a transformation to the data before plotting. For example, users can apply a <code>speedup</code> transformation.</p>
</div>
<div id="examp:0" class="sidebarblock examp">
<div class="content">
<div class="title">Plot for sorting algorithms benchmark</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-json hljs" data-lang="json">{
    "plots":[
        {
            "title":"Complexity",
            "plot_types":["scatter"],
            "transformation":"performance",
            "xaxis":{ "parameter":"elements", "label":"N" },
            "yaxis": {"label":"Execution time (s)"},
            "color_axis":{"parameter":"algorithm","label":"Algorithm"}
        }
    ]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>This configuration will generate a scatter plot with the execution time on the y-axis and the number of elements on the x-axis. The color of the points will represent the algorithm used for sorting.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="../_images/plot_example.png" alt="plot example" width="600">
</div>
</div>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Many plot types are supported. Some of them can take an arbitrary number of parameters by using the <code>extra_axes</code> field.</p>
</div>
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_launching_the_benchmarks"><a class="anchor" href="#_launching_the_benchmarks"></a>7. Launching the benchmarks</h2>
<div class="sectionbody">
<div class="paragraph">
<p>The <code>feelpp-benchmarking-exec</code> command is used to launch the benchmarks. The command is used as follows:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">feelpp-benchmarking-exec --machine-config &lt;machine-config&gt; \
                            --benchmark-config &lt;benchmark-config&gt; \
                            --plots-config &lt;plots-config&gt; \
                            --custom-rfm-config &lt;custom-rfm-config&gt;</code></pre>
</div>
</div>
<div class="paragraph">
<p>Additionally, the <code>-v</code> flag can be used to increase the verbosity, the <code>--dry-run</code> flag can be used to simulate the execution and only generate scheduler scripts without submitting them, and the <code>--website</code> flag can be used to render the final reports and launch an http server to visualize the generated dashboard.</p>
</div>
<div class="paragraph">
<p>The <code>feelpp-benchmarking-exec</code> command will export the ReFrame performance reports, along with a snapshot of the plots configuration used for the current benchmark, and a <em>website_config.json</em> file that contains the information necessary to render the dashboard.</p>
</div>
<div class="paragraph">
<p>There is also a <code>feelpp-benchmarking-render</code> command that is used to render the dashboard using Asciidoc and Antora, from a given website configuration, into a specified modules directory. Using this command allows to tweak figures and the dashboard layout, without having to re-run the benchmarks.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
There are a ton of powerful features of <em>feelpp.benchmarking</em> that were not mentioned in this course, they will be mentioned on the advanced training session, such as working with containers, pruning the parameter space and handling memory (or other) constraints.
</td>
</tr>
</table>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer" style="border-top: 2px solid #e9e9e9; background-color: #fafafa; padding-bottom: 2em; padding-top: 2em;">
    <div class="container" style="display: flex; flex-direction: column; align-items: center; gap: 0.5em;">
        <div>
            <a href="https://www.cemosis.fr">
                <img src="../../../_/img/cemosis-logo.svg" alt="Cemosis logo" height="50">
            </a>
        </div>
        <span style="font-size: 0.8rem; color: #9e9e9e"> 2025 <a href="https://www.cemosis.fr" style="text-decoration: underline;">Cemosis</a>, Universit de Strasbourg</span>
    </div>
</footer>
<script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>


<script async src="../../../_/js/vendor/fontawesome-icon-defs.js"></script>
<script async src="../../../_/js/vendor/fontawesome.js"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>


<script type="text/javascript">
function toggleFullScreen() {
   var doc = window.document;
   var docEl = doc.documentElement;

   var requestFullScreen = docEl.requestFullscreen || docEl.mozRequestFullScreen || docEl.webkitRequestFullScreen || docEl.msRequestFullscreen;
   var cancelFullScreen = doc.exitFullscreen || doc.mozCancelFullScreen || doc.webkitExitFullscreen || doc.msExitFullscreen;

   if(!doc.fullscreenElement && !doc.mozFullScreenElement && !doc.webkitFullscreenElement && !doc.msFullscreenElement) {
       requestFullScreen.call(docEl);
   }
   else {
       cancelFullScreen.call(doc);
   }
}
</script>
  </body>
</html>
