= Benchmark configuration
:page-plotly: true
:page-jupyter: true

Configuring a benchmark can be quite extensive, as this framework focuses on flexibility. For this, the documentation will be divided in main sections.

The benchmark configuration file describes precisely how the benchmarking should be done, for example, specifying where the executable is located, the options to pass to the application, and how the tests will be parametrized.

The base of the configuration file is shown below.
[source,json]
----
{
    "executable": "",
    "use_case_name": "",
    "timeout":"",
    "env_variables":{},
    "options": [],
    "resources":{},
    "platforms":{},
    "additional_files":{},
    "scalability":{},
    "sanity":{},
    "parameters":{},
}
----

[TIP]
====
Users can add any field used for refactoring. For example, one can do the following.

[source,json]
----
"output_directory":"/data/outputs" // This is a custom field
"options":["--output {{output_directory}}"]
----
====

include::benchmark/base.adoc[leveloffset=+1]

include::benchmark/resources.adoc[leveloffset=+1]

include::benchmark/platforms.adoc[leveloffset=+1]

include::benchmark/scalability.adoc[leveloffset=+1]

include::benchmark/additionalFiles.adoc[leveloffset=+1]

include::benchmark/sanity.adoc[leveloffset=+1]

include::benchmark/parameters.adoc[leveloffset=+1]

include::benchmark/fileDependencies.adoc[leveloffset=+1]



== Sanity

The `sanity` field is used to validate the application execution.

The syntax is the following:

[source,json]
----
"sanity":{
    "success":[],
    "error":[]
}
----

- The `success` field contains a list of patterns to look for in the standard output. If any of the patterns are not found, the test will fail.
- The `error` field contains a list of patters that will make the test fail if found in the standard output. If any of these paterns are found, the test will fail.

[NOTE]
====
At the moment, only validating standard output is supported. It will soon be possible to specify custom log files.
====

== Parameters

The `parameters` field list all parameters to be used in the test.
The cartesian product of the elements in this list will determine the benchmarks.

Parameters are accessible across the whole configuration file by using the syntax `{{parameters.my_parameter.value}}`.

Each parameter is described by a name and a generator.

Valid generators are :


- `linspace`:
[source,json]
----
{
    "name": "my_linspace_generator",
    "geomspace":{
        "min":2,
        "max":10,
        "n_steps":5
    }
}
----
The example will yield `[2,4,6,8,10]`. Min and max are inclusive.

- `geomspace`:
[source,json]
----
{
    "name": "my_geomspace_generator",
    "geomspace":{
        "min":1,
        "max":10,
        "n_steps":4
    }
}
----
The example will yield `[2,16,128,1024]`. Min and max are inclusive.

- `range`:
[source,json]
----
{
    "name": "my_range_generator",
    "geomspace":{
        "min":1,
        "max":5,
        "step":1
    }
}
----
The example will yield `[1,2,3,4,5]`. Min and max are inclusive.


- `geometric`:
[source,json]
----
{
    "name": "my_geometric_generator",
    "geometric":{
        "start":1,
        "ratio":2,
        "n_steps":5
    }
}
----
The example will yield `[1,2,4,8,16]`.

- `repeat`:
[source,json]
----
{
    "name": "my_repeat_generator",
    "repeat":{
        "value":"a repeated value",
        "count":3
    }
}
----
The example will yield `["a repeated value", "a repeated value", "a repeated value"]`.

- `sequence`:

Sequence accepts

[source,json]
----
{
    "name": "my_sequence_generator",
    "sequence":[ 1, 2, 3, 4]
}
----
Sequence is the simplest generator. It will yield exactly the given list.
It accepts dictionnaries as items, which can then be accessed via the `.` separator.


- `zip` and subparameters:

Parameters can contain subparameters, which can be accessed recursively via the `.` separator. Its objective is to have parameters that depend on eachother, without producing a cartesian product.
Aditionnaly, parameters can be zipped together via the `zip` generator.
The `zip` generator takes a list of parameters to produce a list of python dictionaries. Each param inside the list can then have any desired generator from above.

[source,json]
----
{
    "name": "my_zip_generator",
    "zip":[
        {
            "name":"param1",
            "sequence":[
                {"val1":1,"val2":2},
                {"val1":3,"val2":4},
                {"val1":5,"val2":6}
            ]
        },
        {
            "name":"param2",
            "repeat":{
                "value":"a repeated value",
                "count":3
            }
        }
    ]
}
----
This example will yield `[{'param1': {'val1': 1, 'val2': 2}, 'param2': 'a repeated value'}, {'param1': {'val1': 3, 'val2': 4}, 'param2': 'a repeated value'}, {'param1': {'val1': 5, 'val2': 6}, 'param2': 'a repeated value'}]`

[WARNING]
====
Zipped parameters need to have the same lenght.
====

- Special parameters

There is one special parameter: `nb_tasks`. If included, should follow some rules for its subparameters.

Accepts `exclusive_access` subparameter. Defaults to `true`.
Either specify `tasks_per_node` and `tasks` subparameters, OR specify `tasks_per_node` and `nodes` subparameters, OR Specify only the `tasks` parameter.

Specifying `tasks` and `nodes` is NOT currently supported.

The `nb_tasks` parameter and its subparameters are directly accesses by ReFrame.

Other parameters have only an impact on the application execution, meaning that they should be passed as options to the executable.

