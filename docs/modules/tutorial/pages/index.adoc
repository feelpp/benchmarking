= feelpp.benchmarkign project

== Introduction

The _Feel++ benchmarking_ project provides a framework for automating, centralizing and organizing performance evaluation of scientific simulations on HPC systems.
This project, based on the ReFrame-hpc[TODO: Link] framework, enables highly customized benchmarking using robust and comprehensive JSON configuration files that parametrize tests, validate executions and generate figures.
It also provides concrete CI/CD/CB pipelines to fully automate the benchmarking step of any application.
TODO...

== Getting started

=== Installation

. Clone the Repository
[source,cmd]
----
git clone https://github.com/feelpp/benchmarking.git
----

. Use a python virtual environment [Optional]
[source,cmd]
----
python3 -m venv .venv
source .venv/bin/activate
----

. Build the project
[source,cmd]
----
pip3 wheel --no-deps --wheel-dir dist .
----

. Install requirements

This will install necessary dependencies as well as the built project from the previous step.
[source,cmd]
----
python3 -m pip install -r requirements.txt
----

=== Initial setup
TODO

== Configuration guide

=== System configuration

=== Magic strings

=== Machine configuration

=== Benchmark configuration

=== Overview configuration

=== Plots configuration

== Benchmarking Workflow

== Interpreting Benchmarks

== CI/CD and Automation

== Versioning

== Advanced usage

== Examples