name: Benchmark

on:
    repository_dispatch:
        types: [execute-benchmark]

    workflow_dispatch:
        inputs:
            hpc-systems:
                description: 'List of systems to run'
                required: True
                default: gaya
            benchmark_config:
                description: 'Path to benchmark configuration'
                required: True
                default: config/toolbox_heat/thermal_bridges_case_3.json
            plots_config:
                description: 'Path to plots related configuration'
                required: True
                default: config/toolbox_heat/heat_plots.json
            upload_id:
                description: 'ID to upload the website to'
                required: False
                default: ""

jobs:

    build_wheel: #Should be removed upon pypi release
        runs-on: self-ubuntu-22.04
        name: Build wheel package
        if: "!contains(github.event.head_commit.message, 'code skip')"
        steps:
        -   uses: actions/checkout@v4
        -   name: Build wheel
            run: |
                npm install
                npx downdoc README.adoc
                pip3 wheel --no-deps --wheel-dir dist .
            env:
                CXX: clang++
        -   name: Upload Artifact
            uses: actions/upload-artifact@v4
            with:
                name: wheel-artifacts
                path: dist/*.whl

    factory:
        name: HPC Systems Factory
        runs-on: self-ubuntu-22.04
        outputs:
            matrix: ${{ steps.hpc-systems.outputs.matrix }}
            executable_name: ${{ steps.gather_arguments.outputs.executable_name }}
            use_case: ${{ steps.gather_arguments.outputs.use_case }}
        steps:

        -   name: Get machines configuration
            id: download_systems_config
            run: |
                machine_config=$(curl -H 'Authorization: token ${{ secrets.CR_PAT }}' https://raw.githubusercontent.com/feelpp/hpc-systems/refs/heads/main/systems.json)
                machine_config=$(jq --compact-output '' <<< $machine_config)
                echo "machine_config=$machine_config" >> $GITHUB_OUTPUT

        -   name: Filter systems and set matrix
            id: hpc-systems
            run: |
                valid_systems=${{ github.event.inputs.hpc-systems || github.event.client_payload.hpc-systems }}
                machine_config='${{ steps.download_systems_config.outputs.machine_config }}'

                filtered_systems_config=$(echo "$machine_config" | jq --arg valid_systems "$valid_systems" '
                    ($valid_systems | split(",")) as $systems |
                    with_entries(select([.key] | inside($systems))) | [.[]]
                ')
                echo "matrix=$(jq -c --null-input --argjson config "$filtered_systems_config" '{include: $config}')" >> $GITHUB_OUTPUT

        -   uses: actions/checkout@v4

        -   name: Gather arguments
            id: gather_arguments
            run: |
                echo "executable_name=$(jq -r '.executable' ${{ github.event.inputs.benchmark_config || github.event.client_payload.benchmark_config }})" >> $GITHUB_OUTPUT
                echo "use_case=$(jq -r '.use_case_name' ${{ github.event.inputs.benchmark_config || github.event.client_payload.benchmark_config }})" >> $GITHUB_OUTPUT

        -   name: Upload configs
            uses: actions/upload-artifact@v4
            with:
                name: config-artifacts
                path: |
                    ${{ github.event.inputs.benchmark_config || github.event.client_payload.benchmark_config }}
                    ${{ github.event.inputs.plots_config || github.event.client_payload.plots_config}}

    benchmark:
        needs: [build_wheel,factory]
        strategy:
            fail-fast: false
            matrix: ${{ fromJson(needs.factory.outputs.matrix) }}
        runs-on: ${{matrix.runner_tag}}
        timeout-minutes: 7200
        name: ${{matrix.machine}}
        steps:
        -   uses: actions/checkout@v4
        -   name: Download wheel
            uses: actions/download-artifact@v4
            with:
                name: wheel-artifacts
                path: dist
        -   name: Download configs
            uses: actions/download-artifact@v4
            with:
                name: config-artifacts
                path: ./tmp/
        -   name: Create machine config
            run: |
                echo "${{ toJson(matrix.system_config) }}" >> ./tmp/machine_config.json
        -   name: Setup machine and env
            run: sh ./src/feelpp/benchmarking/reframe/config/machineConfigs/${{matrix.machine}}.sh
        -   name: Execute benchmarks
            run: |
                source .venv/bin/activate
                execute-benchmark \
                    -mc ./tmp/machine_config.json \
                    -bc ./tmp/benchmark_config.json \
                    -pc ./tmp/plots.json \
                    -v
        -   name: Upload reframe report
            uses: actions/upload-artifact@v4
            with:
                name: benchmark-results-${{matrix.machine}}
                path: ${{matrix.reports_base_dir}}

    deploy:
        runs-on: self-ubuntu-22.04
        needs: [benchmark,factory]
        name: Handle results and trigger rendering
        if: ${{ github.event.inputs.upload_id == '' && github.event.client_payload.upload_id == '' }}
        steps:
        -   uses: actions/checkout@v4
        -   name: Download results
            uses: actions/download-artifact@v4
            with:
                pattern: benchmark-results-*
                path: ./tmp/results/
                merge-multiple: false
        -   name: Create Virtual Environment
            run: |
                python3 -m venv .venv
                source .venv/bin/activate
                pip3 install -r requirements.txt
        -   name: Upload to girder
            run: |
                source .venv/bin/activate
                source ./girder_deploy_config.sh
                girder-upload --item "./tmp/results/*" --girder_id $staging_folder_id
            env:
                GIRDER_API_KEY: ${{ secrets.GIRDER }}
        -   name: Update Index Date
            run: |
                sed -i "s/^:docdatetime: .*/:docdatetime: $(date +'%Y-%m-%dT%H:%M:%S')/" "docs/modules/ROOT/pages/index.adoc"
        -   name: Create Pull Request
            uses: peter-evans/create-pull-request@v7
            with:
                title: "Add benchmark for ${{ needs.factory.outputs.executable_name }} - ${{ needs.factory.outputs.use_case }}"
                commit-message: "Add benchmark for ${{ needs.factory.outputs.executable_name }} - ${{ needs.factory.outputs.use_case }}"
                body: |
                    Generating reports from staging directory.
                    Auto-generated by [create-pull-request][1]
                    [1]: https://github.com/peter-evans/create-pull-request
                reviewers: JavierCladellas
                labels: new-benchmark
                branch: new-benchmark
            env:
                GITHUB_TOKEN: ${{ secrets.CR_PAT }}

    user-results:
        runs-on: self-ubuntu-22.04
        needs: [benchmark,factory]
        name: Deploy the website to a specific folder
        if: ${{ github.event.inputs.upload_id != '' || github.event.client_payload.upload_id != '' }}
        steps:
            -   uses: actions/checkout@v4
            -   name: Download results
                uses: actions/download-artifact@v4
                with:
                    pattern: benchmark-results-*
                    path: ./tmp/results/
                    merge-multiple: false
            -   name: Create Virtual Environment
                run: |
                    python3 -m venv .venv
                    source .venv/bin/activate
                    pip3 install -r requirements.txt
            -   name: Merge website configs
                run: |
                    source .venv/bin/activate
                    merge-json-configs -fp "./tmp/**/website_config.json" -o ./tmp/website_config.json -u
            -   name: Render docs
                run: |
                    source .venv/bin/activate
                    render-benchmarks --config-file=./tmp/website_config.json
            -   name: Compile docs
                run: |
                    source .venv/bin/activate
                    npm install
                    npm run antora
            -   name: Upload
                run: |
                    source .venv/bin/activate
                    if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
                        upload_id=${{ github.event.inputs.upload_id }};
                    elif [[ "${{ github.event_name}}" == "repository_dispatch" ]]; then
                        upload_id=${{ github.event.client_payload.upload_id }};
                    fi
                    girder-upload --item "./tmp/results/*" --girder_id $upload_id
                    girder-upload --item "./public/" --girder_id $upload_id
                env:
                    GIRDER_API_KEY: ${{secrets.GIRDER}}

